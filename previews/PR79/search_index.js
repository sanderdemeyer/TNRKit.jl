var documenterSearchIndex = {"docs":
[{"location":"references/#References","page":"References","title":"References","text":"","category":"section"},{"location":"references/","page":"References","title":"References","text":"Adachi, D.; Okubo, T. and Todo, S. (2020). Anisotropic tensor renormalization group. Physical Review B 102, 054432. Accessed on Mar 4, 2025. Publisher: American Physical Society.\n\n\n\nAdachi, D.; Okubo, T. and Todo, S. (2022). Bond-weighted tensor renormalization group. Physical Review B 105, L060402. Accessed on Nov 18, 2024. Publisher: American Physical Society.\n\n\n\nLevin, M. and Nave, C. P. (2007). Tensor Renormalization Group Approach to Two-Dimensional Classical Lattice Models. Physical Review Letters 99, 120601. Accessed on Feb 10, 2025. Publisher: American Physical Society.\n\n\n\nXie, Z. Y.; Chen, J.; Qin, M. P.; Zhu, J. W.; Yang, L. P. and Xiang, T. (2012). Coarse-graining renormalization by higher-order singular value decomposition. Physical Review B 86, 045139. Accessed on May 24, 2025. Publisher: American Physical Society.\n\n\n\nYang, S.; Gu, Z.-C. and Wen, X.-G. (2017). Loop Optimization for Tensor Network Renormalization. Physical Review Letters 118, 110504. Accessed on Dec 3, 2024. Publisher: American Physical Society.\n\n\n\n","category":"page"},{"location":"lib/lib/#Library-documentation","page":"Library","title":"Library documentation","text":"","category":"section"},{"location":"lib/lib/#TNRKit.ATRG","page":"Library","title":"TNRKit.ATRG","text":"mutable struct ATRG <: TNRScheme\n\nAnisotropic Tensor Renormalization Group\n\nConstructors\n\nATRG(T [, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::ATRG, trunc::TensorKit.TruncationSheme, stop::Stopcrit[, finalize_beginning=true, verbosity=1])\n\nEach step rescales the lattice by a (linear) factor of √2\n\ninfo: verbosity levels\n0: No output\n1: Print information at start and end of the algorithm\n2: Print information at each step\n\nFields\n\nT::TensorKit.TensorMap\nfinalize!::Function\n\nReferences\n\nAdachi et. al. Phys. Rev. B 102 (2020)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.ATRG_3D","page":"Library","title":"TNRKit.ATRG_3D","text":"mutable struct ATRG_3D <: TNRScheme\n\n3D Anisotropic Tensor Renormalization Group\n\nConstructors\n\nATRG_3D(T [, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::ATRG_3D, trunc::TensorKit.TruncationSheme, stop::Stopcrit[, finalize_beginning=true,verbosity=1])\n\nEach step rescales the lattice by a (linear) factor of 2\n\ninfo: verbosity levels\n0: No output\n1: Print information at start and end of the algorithm\n2: Print information at each step\n\nFields\n\nT::TensorKit.TensorMap\nfinalize!::Function\n\nReferences\n\nAdachi et. al. Phys. Rev. B 102 (2020)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.BTRG","page":"Library","title":"TNRKit.BTRG","text":"mutable struct BTRG <: TNRScheme\n\nBond-weighted Tensor Renormalization Group\n\nConstructors\n\nBTRG(T [, k=-1/2, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::BTRG, trunc::TensorKit.TruncationSheme, stop::Stopcrit[, finalize_beginning=true, verbosity=1])\n\nEach step rescales the lattice by a (linear) factor of √2\n\ninfo: verbosity levels\n0: No output\n1: Print information at start and end of the algorithm\n2: Print information at each step\n\nFields\n\nT::TensorKit.TensorMap\nS1::TensorKit.TensorMap\nS2::TensorKit.TensorMap\nk::Float64\nfinalize!::Function\n\nReferences\n\nAdachi et. al. Phys. Rev. B 105 (2022)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.HOTRG","page":"Library","title":"TNRKit.HOTRG","text":"mutable struct HOTRG <: TNRScheme\n\nHigher-Order Tensor Renormalization Group\n\nConstructors\n\nHOTRG(T [, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::HOTRG, trunc::TensorKit.TruncationSheme, stop::Stopcrit[, finalize_beginning=true, verbosity=1])\n\nEach step rescales the lattice by a (linear) factor of 2\n\ninfo: verbosity levels\n0: No output\n1: Print information at start and end of the algorithm\n2: Print information at each step\n\nFields\n\nT::TensorKit.TensorMap\nfinalize!::Function\n\nReferences\n\nXie et. al. Phys. Rev. B 86 (2012)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.LoopTNR","page":"Library","title":"TNRKit.LoopTNR","text":"mutable struct LoopTNR <: TNRScheme\n\nLoop Optimization for Tensor Network Renormalization\n\nConstructors\n\nLoopTNR(T [, finalize=finalize!])\nLoopTNR(TA, TB, [, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::LoopTNR, trunc::TensorKit.TruncationScheme, truncentanglement::TensorKit.TruncationScheme, criterion::stopcrit,\n          entanglement_criterion::stopcrit, loop_criterion::stopcrit[, finalize_beginning=true, verbosity=1])\n\nrun!(::LoopTNR, trscheme::TensorKit.TruncationScheme, criterion::stopcrit[, finalize_beginning=true, verbosity=1])\n\nFields\n\nTA::TensorKit.TensorMap\nTB::TensorKit.TensorMap\nfinalize!::Function\n\nReferences\n\nYang et. al. Phys. Rev. Letters 118 (2017)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.SLoopTNR","page":"Library","title":"TNRKit.SLoopTNR","text":"mutable struct SLoopTNR <: TNRScheme\n\nc4 & inversion symmetric Loop Optimization for Tensor Network Renormalization\n\nConstructors\n\nSLoopTNR(T [, finalize=finalize!])\nSLoopTNR(TA, TB, [, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::SLoopTNR, trscheme::TensorKit.TruncationScheme,\n          criterion::TNRKit.stopcrit[, finalize_beginning=true, oneloop=true,\n          verbosity=1])\n\noneloop=true will use disentangled tensors as a starting guess for the optimization.\n\nFields\n\nT::TensorKit.TensorMap\ngradalg::OptimKit.LBFGS\nfinalize!::Function\n\nReferences\n\nYang et. al. Phys. Rev. Letters 118 (2017) (Fig. S6)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.TRG","page":"Library","title":"TNRKit.TRG","text":"mutable struct TRG <: TNRScheme\n\nTensor Renormalization Group\n\nConstructors\n\nTRG(T [, finalize=finalize!])\n\nRunning the algorithm\n\nrun!(::TRG, trunc::TensorKit.TruncationSheme, stop::Stopcrit[, finalize_beginning=true, verbosity=1])\n\nEach step rescales the lattice by a (linear) factor of √2\n\ninfo: verbosity levels\n0: No output\n1: Print information at start and end of the algorithm\n2: Print information at each step\n\nFields\n\nT::TensorKit.TensorMap: central tensor\nfinalize!::Function: finalization function\n\nReferences\n\nLevin & Nave Phys. Rev. Letters 99(12) (2007)\n\n\n\n\n\n","category":"type"},{"location":"lib/lib/#TNRKit.central_charge-Tuple{TNRScheme, Number}","page":"Library","title":"TNRKit.central_charge","text":"central_charge(scheme::TNRScheme, n::Number)\n\nGet the central charge given the current state of a TNRScheme and the previous normalization factor n\n\n\n\n\n\n","category":"method"},{"location":"#TNRKit","page":"Home","title":"TNRKit","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Your one-stop-shop for Tensor Network Renormalization.","category":"page"},{"location":"#Package-summary","page":"Home","title":"Package summary","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TNRKit.jl aims to provide as many Tensor Network Renormalization methods as possible. Several models like the classical Ising, Potts and Six Vertex models are provided.","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can use TNRKit for calculating:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Partition functions (classical & quantum)\nCFT data\nCentral charges","category":"page"},{"location":"","page":"Home","title":"Home","text":"Many common TNR schemes have already been implemented:","category":"page"},{"location":"","page":"Home","title":"Home","text":"2D square tensor networks","category":"page"},{"location":"","page":"Home","title":"Home","text":"TRG (Levin and Nave's Tensor Renormalization Group)\nBTRG (bond-weighted TRG)\nLoopTNR (entanglement filtering + loop optimization)\nSLoopTNR (c4 & inversion symmetric LoopTNR)\nHOTRG (higher order TRG)\nATRG (anisotropic TRG)","category":"page"},{"location":"","page":"Home","title":"Home","text":"CTM methods (yet to be documented)","category":"page"},{"location":"","page":"Home","title":"Home","text":"ctm_TRG (Corner Transfer Matrix environment + TRG)\nctm_HOTRG (Corner Transfer Matrix environment + HOTRG)\nc4CTM (c4 symmetric CTM)\nrCTM (reflection symmetric CTM)","category":"page"},{"location":"","page":"Home","title":"Home","text":"3D cubic tensor networks","category":"page"},{"location":"","page":"Home","title":"Home","text":"ATRG_3D (anisotropic TRG)","category":"page"},{"location":"#Quick-Start-Guide","page":"Home","title":"Quick Start Guide","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Choose a (TensorKit!) tensor that respects the leg-convention (see below)\nChoose a TNR scheme\nChoose a truncation scheme\nChoose a stopping criterion","category":"page"},{"location":"","page":"Home","title":"Home","text":"For example:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TNRKit, TensorKit\n\nT = classical_ising_symmetric(ising_βc) # partition function of classical Ising model at the critical point\nscheme = BTRG(T) # Bond-weighted TRG (excellent choice)\ndata = run!(scheme, truncdim(16), maxiter(25)) # max bond-dimension of 16, for 25 iterations","category":"page"},{"location":"","page":"Home","title":"Home","text":"data now contains 26 norms of the tensor, 1 for every time the tensor was normalized. (By default there is a normalization step before the first coarse-graining step wich can be turned off by changing the kwarg run!(...; finalize_beginning=false))","category":"page"},{"location":"","page":"Home","title":"Home","text":"Using these norms you could, for example, calculate the free energy of the critical classical Ising model:","category":"page"},{"location":"","page":"Home","title":"Home","text":"lnz = 0\nfor (i, d) in enumerate(data)\n    lnz += log(d) * 2.0^(1 - i)\nend\n\nf_ising = lnz * -1 / ising_βc","category":"page"},{"location":"","page":"Home","title":"Home","text":"You could even compare to the exact value, as calculated by Onsager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> abs((fs - f_onsager) / f_onsager)\n3.1e-07","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pretty impressive for a calculation that takes about 0.3s on a laptop.","category":"page"},{"location":"#Verbosity","page":"Home","title":"Verbosity","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"There are 3 levels of verbosity implemented in TNRKit:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Level 0: no TNRKit messages whatsoever.\nLevel 1: Info at beginning and end of the simulations (including information on why the simulation stopped, how long it took and how many iterations were performed).\nLevel 2: Level 1 + info at every iteration about the last generated finalize output and the iteration number.","category":"page"},{"location":"","page":"Home","title":"Home","text":"to choose the verbosity level, simply use run!(...; verbosity=n). The default is verbosity=1.","category":"page"},{"location":"#Included-Models","page":"Home","title":"Included Models","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TNRKit includes several common models out of the box.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ising model: classical_ising(β; h=0) and classical_ising_symmetric(β), which has a Z2 grading on each leg.\nPotts model: classical_potts(q, β) and classical_potts_symetric(q, β), which has a Zq grading on each leg.\nSix Vertex model: sixvertex(scalartype, spacetype; a=1.0, b=1.0, c=1.0)\nClock model: classical_clock","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you want to implement your own model you must respect the leg-convention assumed by all TNRKit schemes.","category":"page"},{"location":"#Leg-convention","page":"Home","title":"Leg-convention","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"All the schemes assume that the input tensor lives in the space V_1 otimes V_2 leftarrow V_3 otimes V_4 and that the legs are ordered in the following way:","category":"page"},{"location":"","page":"Home","title":"Home","text":"     3\n     |\n     v\n     |\n1-<--┼--<-4\n     |\n     v\n     |\n     2","category":"page"},{"location":"","page":"Home","title":"Home","text":"The 3D scheme(s) assume that the input tensor lives in the space V_textD otimes V_textU prime leftarrow V_textN otimes V_textE otimes V_textS prime otimes V_textW prime.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Where D, U, N, E, S, W stand for Down, Up, North, East, South and West.","category":"page"}]
}
